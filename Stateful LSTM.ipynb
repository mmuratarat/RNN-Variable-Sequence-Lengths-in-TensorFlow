{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafamuratarat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2,3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1, #fraction of the memory of the GPU \n",
    "                            allow_growth = True,#If TRUE, use a fraction of between 0 and per process gpu memory fraction. If FALSE, pre-allocate entire GPU memory.\n",
    "                            visible_device_list = \"2,3\") #GPUs 2nd and 3rd used out of 0,1,2,3.\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "print(config.gpu_options.per_process_gpu_memory_fraction)\n",
    "print(config.gpu_options.visible_device_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train.txt', header=None).as_matrix()\n",
    "y_train = pd.read_csv('y_train.txt', header=None).as_matrix().ravel()\n",
    "X_test = pd.read_csv('X_test.txt', header=None).as_matrix()\n",
    "y_test = pd.read_csv('y_test.txt', header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y is a array. labelNum is number of distinct values in y, an integer. \n",
    "def convertDummy(y, labelNum):#This is a function one-hot encoding the classes. \n",
    "    labelNum = tf.constant(labelNum) #Construct pre-allocation labelNum.\n",
    "    dummy = tf.one_hot(y, labelNum, axis=1) #Construct operations to create labelNum times columns\n",
    "    sess = tf.Session(config=config) #Defining the session \n",
    "    dummy = sess.run(dummy) #Execute the session\n",
    "    sess.close() #closing the session\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Batching datarows\n",
    "#It will return a list of tuples.\n",
    "def miniBatch(x, y, batchSize):\n",
    "    numObs  = x.shape[0]\n",
    "    batches = [] \n",
    "    batchNum = math.floor(numObs / batchSize)\n",
    "\n",
    "    for i in range(batchNum - 1):\n",
    "        xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "        yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "        batches.append((xBatch, yBatch))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing the length of sequences. It is needed for variable length sequences\n",
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    sess = tf.Session(config=config)\n",
    "    length = sess.run(length)\n",
    "    sess.close()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_timestep = 60\n",
    "num_classes = 6\n",
    "split_size = max_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_time(m, split_size):\n",
    "        r = m.shape[0]\n",
    "        extend_row_size = np.math.ceil(r / split_size) * split_size - r\n",
    "        m_p = np.expand_dims(np.pad(m, [(0, extend_row_size), (0, 0)], mode='constant'), axis=0)\n",
    "        result = m_p.reshape((np.math.ceil(r / split_size), split_size, m.shape[1]))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = split_time(X_train, split_size)\n",
    "ytrain = split_time(convertDummy(y_train-1, num_classes), split_size)\n",
    "Xtest = split_time(X_test, split_size)\n",
    "ytest = split_time(convertDummy(y_test-1, num_classes), split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 60, 561)\n",
      "(123, 60, 6)\n",
      "(50, 60, 561)\n",
      "(50, 60, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state_variables(batch_size, cell):\n",
    "    # For each layer, get the initial state and make a variable out of it\n",
    "    # to enable updating its value.\n",
    "    state_variables = []\n",
    "    for state_c, state_h in cell.zero_state(batch_size, tf.float32):\n",
    "        state_variables.append(tf.contrib.rnn.LSTMStateTuple(\n",
    "            tf.Variable(state_c, trainable=False),\n",
    "            tf.Variable(state_h, trainable=False)))\n",
    "    # Return as a tuple, so that it can be fed to dynamic_rnn as an initial state\n",
    "    return tuple(state_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state_update_op(state_variables, new_states):\n",
    "    # Add an operation to update the train states with the last state tensors\n",
    "    update_ops = []\n",
    "    for state_variable, new_state in zip(state_variables, new_states):\n",
    "        # Assign the new state to the state variables on this layer\n",
    "        update_ops.extend([state_variable[0].assign(new_state[0]),\n",
    "                           state_variable[1].assign(new_state[1])])\n",
    "    # Return a tuple in order to combine all update_ops into a single operation.\n",
    "    # The tuple's actual value should not be used.\n",
    "    return tf.tuple(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=3\n",
    "num_neurons = 128\n",
    "num_inputs = Xtrain.shape[2] #561\n",
    "num_classes = ytrain.shape[2] #6\n",
    "num_steps=Xtrain.shape[1] #60\n",
    "\n",
    "#Configuration\n",
    "learning_rate = 0.01\n",
    "train_keep_prob = 0.5\n",
    "batch_size =16\n",
    "#During training, you can feed any value you want to the keep_prob placeholder (typically 0.5)\n",
    "train_keep_prob =0.5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_steps, num_inputs], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, [None, None, num_classes], name='labels_placeholder')\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2)\n",
    "#LSTM layers\n",
    "#It can take a while for a recurrent network to learn to remember information from the last time step. \n",
    "#Initialize biases for LSTMâ€™s forget gate to 1 to remember more by default\n",
    "#This is default non-peephole implementation\n",
    "lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=num_neurons, forget_bias=1.0, initializer=initializer, state_is_tuple=True) for layer in range(num_layers)]\n",
    "#Dropout layer before and after each LSTM cells\n",
    "lstm_cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob) for cell in lstm_cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells_drop, state_is_tuple=True)\n",
    "\n",
    "init_states = tf.placeholder(tf.float32, [num_layers, 2, batch_size, num_neurons])\n",
    "#init_states = multi_layer_cell.zero_state(tf.shape(X)[0], tf.float32)\n",
    "#init_states = tf.identity(init_states, \"init_states\")\n",
    "state_per_layer_list = tf.unstack(init_states, axis=0)\n",
    "rnn_tuple_state = tuple([tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1]) for idx in range(num_layers)])\n",
    "\n",
    "\n",
    "# time_major = False: (batch, time step, input); time_major = True: (time step, batch, input)\n",
    "#The default approach to initializing the state of an RNN is to use a zero state\n",
    "outputs, final_state = tf.nn.dynamic_rnn(multi_layer_cell, X, sequence_length= seq_length, time_major = False, initial_state=rnn_tuple_state, dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    _current_state = np.zeros((num_layers, 2, batch_size, num_neurons))\n",
    "    miniBatches = miniBatch(Xtrain, ytrain, batch_size)\n",
    "    batchNum = len(miniBatches)\n",
    "    for batch in miniBatches:\n",
    "        xBatch = batch[0]\n",
    "        yBatch = batch[1]\n",
    "        seq_length_batch = length(xBatch)\n",
    "        #if you use zero_state you do not need _current_state and assigning a placeholder for it. \n",
    "        outputs_val, final_state_val = sess.run([outputs, final_state], feed_dict={X: xBatch, y: yBatch, seq_length: seq_length_batch, keep_prob:train_keep_prob, init_states: _current_state})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
