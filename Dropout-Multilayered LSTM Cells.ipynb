{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafamuratarat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train.txt', header=None).as_matrix()\n",
    "y_train = pd.read_csv('y_train.txt', header=None).as_matrix().ravel()\n",
    "X_test = pd.read_csv('X_test.txt', header=None).as_matrix()\n",
    "y_test = pd.read_csv('y_test.txt', header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertDummy(y, labelNum):\n",
    "    labelNum = tf.constant(labelNum)\n",
    "    dummy = tf.one_hot(y, labelNum, axis=1)\n",
    "    sess = tf.Session()\n",
    "    dummy = sess.run(dummy)\n",
    "    sess.close()\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  sess = tf.Session()\n",
    "  length = sess.run(length)\n",
    "  sess.close()\n",
    "  return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def miniBatch(x, y, batchSize):\n",
    "    numObs  = x.shape[0]\n",
    "    batches = []\n",
    "    batchNum = math.floor(numObs / batchSize)\n",
    "\n",
    "    for i in range(batchNum - 1):\n",
    "        xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "        yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "        batches.append((xBatch, yBatch))\n",
    "    xBatch = x[batchNum * batchSize:, :]\n",
    "    yBatch = y[batchNum * batchSize:, :]\n",
    "    batches.append((xBatch, yBatch))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_timestep = 60\n",
    "num_classes = 6\n",
    "split_size = max_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def split_time(m, split_size):\n",
    "        r = m.shape[0]\n",
    "        extend_row_size = np.math.ceil(r / split_size) * split_size - r\n",
    "        m_p = np.expand_dims(np.pad(m, [(0, extend_row_size), (0, 0)], mode='constant'), axis=0)\n",
    "        result = m_p.reshape((np.math.ceil(r / split_size), split_size, m.shape[1]))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = split_time(X_train, split_size)\n",
    "ytrain = split_time(convertDummy(y_train-1, num_classes), split_size)\n",
    "Xtest = split_time(X_test, split_size)\n",
    "ytest = split_time(convertDummy(y_test-1, num_classes), split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 60, 561)\n",
      "(123, 60, 6)\n",
      "(50, 60, 561)\n",
      "(50, 60, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
       "       60, 60, 60, 32], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(Xtrain) #the last instance has only 32 time steps. We left-pad them with zeroes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you build a very deep LSTM, it may end up overfitting the training set. In order to prevent that, a common technique is to apply dropout. You can simply add a dropout layer before or after the LSTM as usual but if you also want to apply dropout between LSTM layers, you need to use a DropoutWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_neurons = 128\n",
    "num_inputs = 561\n",
    "num_classes = 6\n",
    "num_steps=60\n",
    "num_iterations = 100\n",
    "num_layers=3\n",
    "\n",
    "#During training, you can feed any value you want to the keep_prob placeholder (typically 0.5)\n",
    "train_keep_prob =0.5\n",
    "\n",
    "seq_length_batch = length(Xtrain)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_steps, num_inputs])\n",
    "y = tf.placeholder(tf.int64, [None, None, num_classes])\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "initializer = tf.random_uniform_initializer(-1, 1)\n",
    "lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=num_neurons, state_is_tuple=True, forget_bias=1.0, initializer=initializer) for layer in range(num_layers)]\n",
    "lstm_cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob) for cell in lstm_cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells_drop)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: Xtrain, seq_length: seq_length_batch, keep_prob: train_keep_prob})\n",
    "\n",
    "#states variable is a tuple containing one tensor per layer, each representing the final state of that layer's cell\n",
    "#with shape [batch_size X num_neurons]\n",
    "\n",
    "#states_val[2] is the tuple for the last layer. It has two arrays in it , one for hidden state h_state, \n",
    "#the other for memory state c_state.\n",
    "\n",
    "#states_val[2][1].shape hidden state has the shape (123, 128), which is [batch_size X num_neurons] \n",
    "#that we mentioned above.\n",
    "\n",
    "\n",
    "#the hidden state of the last layer in states tuple will be the same with the last time-step of outputs \n",
    "#for one particular observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=array([[-6.7680970e-02,  9.1396743e-01,  9.9923646e-01, ...,\n",
       "         1.0229808e+00,  1.7731071e+00,  2.4362956e-01],\n",
       "       [ 1.4840257e+00, -1.6282718e+00,  1.4953713e+00, ...,\n",
       "        -8.5468493e-02, -1.2305751e+00, -8.5696262e-01],\n",
       "       [-9.4343626e-01,  5.9862161e-01, -5.7227069e-01, ...,\n",
       "         2.3866761e-02, -4.5293739e-01,  1.3368111e-03],\n",
       "       ...,\n",
       "       [-9.2974854e-01, -2.0055228e-01,  7.7674824e-01, ...,\n",
       "         4.9443191e-01,  8.8370866e-01, -2.2136122e-03],\n",
       "       [ 3.9246514e-02, -1.2646917e-01, -2.0961554e-01, ...,\n",
       "        -2.9355648e-01, -1.0848233e-01, -4.5372680e-02],\n",
       "       [ 4.8759878e-02, -4.2822036e-01,  4.2377287e-01, ...,\n",
       "        -9.1928977e-01,  1.5365555e+00,  8.9523041e-01]], dtype=float32), h=array([[-1.4614449e-03,  4.1632261e-03,  6.1467177e-01, ...,\n",
       "         7.7088445e-01,  4.4296119e-01,  2.3714852e-01],\n",
       "       [ 6.7463249e-01, -1.3774876e-01,  7.5513667e-01, ...,\n",
       "        -4.3386869e-02, -7.5190824e-01, -1.2458118e-01],\n",
       "       [-1.0695696e-02,  3.2559170e-03, -5.1672304e-01, ...,\n",
       "         5.8894104e-05, -6.6337928e-02,  1.2593768e-03],\n",
       "       ...,\n",
       "       [-7.3023546e-01, -1.9712321e-01,  5.4006213e-01, ...,\n",
       "         2.8412770e-02,  6.8838102e-01, -2.1686032e-03],\n",
       "       [ 3.7992109e-02, -1.1614889e-01, -1.7354730e-01, ...,\n",
       "        -2.7856332e-01, -2.2691963e-02, -1.4159575e-03],\n",
       "       [ 5.1614651e-03, -8.4389210e-02,  3.8470507e-01, ...,\n",
       "        -6.1974293e-01,  3.5957113e-02,  4.6775810e-02]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46144489e-03,  4.16322611e-03,  6.14671767e-01,  5.14349900e-02,\n",
       "        9.80566163e-03,  1.13957962e-04, -7.48810351e-01, -3.20786843e-04,\n",
       "        7.59860426e-02,  5.62000394e-01, -9.23652470e-01, -1.01787165e-01,\n",
       "       -1.71003165e-03, -4.18778621e-02, -5.71841121e-01,  4.38588113e-03,\n",
       "        4.09034640e-01, -7.33205210e-03, -5.77882957e-03, -5.62575579e-01,\n",
       "       -8.00679445e-01,  6.86107039e-01, -6.51394352e-02, -2.44840831e-01,\n",
       "        4.28312629e-01, -2.79166661e-02,  2.77712375e-01,  6.22436055e-05,\n",
       "       -2.19905391e-01, -1.78232878e-01, -2.94782333e-02, -2.70124108e-01,\n",
       "        1.37052964e-03, -2.62694862e-02, -7.13243634e-02, -6.28041178e-02,\n",
       "        8.88245165e-01,  8.26203376e-02,  5.75758219e-01,  6.21252418e-01,\n",
       "        4.51927044e-05, -8.82703602e-01,  8.04276109e-01,  1.94275672e-05,\n",
       "       -8.63878667e-01, -2.24489853e-01, -1.59137268e-02,  4.58719939e-01,\n",
       "        1.20201118e-01, -7.36764193e-01, -2.04624087e-02,  6.41722322e-01,\n",
       "        4.19830641e-04, -9.92955267e-02, -1.08837493e-01, -4.78977477e-03,\n",
       "       -1.92839965e-01, -3.35875507e-06,  4.99942899e-03,  2.06053089e-02,\n",
       "        1.84529927e-04, -7.38855839e-01,  8.81200135e-01,  2.74463218e-05,\n",
       "       -3.39525372e-01, -4.37694579e-01, -7.43322000e-02,  5.81778824e-01,\n",
       "        9.16686986e-05,  5.96023083e-01, -1.00301169e-01,  2.20887456e-02,\n",
       "        3.49493213e-02,  2.87792474e-01,  4.40622754e-02,  4.32757027e-02,\n",
       "       -1.33844716e-02,  7.26311782e-06, -5.66090597e-03,  5.07286675e-02,\n",
       "        4.70942352e-03,  2.65480038e-02, -6.11170270e-02,  8.96223664e-01,\n",
       "       -4.62108627e-02, -2.56462812e-01,  1.33210212e-01,  4.47214901e-01,\n",
       "       -3.07969123e-01,  1.42379748e-02, -1.33383289e-01,  3.49293947e-01,\n",
       "        5.04339598e-02, -2.37676520e-02, -2.59640981e-02, -4.95776713e-01,\n",
       "       -1.01602525e-01,  2.35280976e-01, -9.69712615e-01,  5.67660332e-01,\n",
       "        1.43065751e-01,  1.42124640e-02,  5.88513732e-01, -2.73607224e-01,\n",
       "        1.69000223e-01,  1.54676825e-01,  2.07075417e-01, -2.87804268e-02,\n",
       "        1.38141577e-05, -6.15064315e-02,  4.16748747e-02, -1.16062896e-04,\n",
       "       -3.97272594e-02, -5.68113863e-01,  6.02727354e-01, -1.69804439e-01,\n",
       "        1.69194750e-02,  5.79919331e-02,  1.86641403e-02, -1.14388340e-05,\n",
       "        3.94161254e-01,  8.82430732e-01,  1.38182834e-01, -6.98341489e-01,\n",
       "       -1.55580744e-01,  7.70884454e-01,  4.42961186e-01,  2.37148523e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_val[0][59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46144489e-03,  4.16322611e-03,  6.14671767e-01,  5.14349900e-02,\n",
       "        9.80566163e-03,  1.13957962e-04, -7.48810351e-01, -3.20786843e-04,\n",
       "        7.59860426e-02,  5.62000394e-01, -9.23652470e-01, -1.01787165e-01,\n",
       "       -1.71003165e-03, -4.18778621e-02, -5.71841121e-01,  4.38588113e-03,\n",
       "        4.09034640e-01, -7.33205210e-03, -5.77882957e-03, -5.62575579e-01,\n",
       "       -8.00679445e-01,  6.86107039e-01, -6.51394352e-02, -2.44840831e-01,\n",
       "        4.28312629e-01, -2.79166661e-02,  2.77712375e-01,  6.22436055e-05,\n",
       "       -2.19905391e-01, -1.78232878e-01, -2.94782333e-02, -2.70124108e-01,\n",
       "        1.37052964e-03, -2.62694862e-02, -7.13243634e-02, -6.28041178e-02,\n",
       "        8.88245165e-01,  8.26203376e-02,  5.75758219e-01,  6.21252418e-01,\n",
       "        4.51927044e-05, -8.82703602e-01,  8.04276109e-01,  1.94275672e-05,\n",
       "       -8.63878667e-01, -2.24489853e-01, -1.59137268e-02,  4.58719939e-01,\n",
       "        1.20201118e-01, -7.36764193e-01, -2.04624087e-02,  6.41722322e-01,\n",
       "        4.19830641e-04, -9.92955267e-02, -1.08837493e-01, -4.78977477e-03,\n",
       "       -1.92839965e-01, -3.35875507e-06,  4.99942899e-03,  2.06053089e-02,\n",
       "        1.84529927e-04, -7.38855839e-01,  8.81200135e-01,  2.74463218e-05,\n",
       "       -3.39525372e-01, -4.37694579e-01, -7.43322000e-02,  5.81778824e-01,\n",
       "        9.16686986e-05,  5.96023083e-01, -1.00301169e-01,  2.20887456e-02,\n",
       "        3.49493213e-02,  2.87792474e-01,  4.40622754e-02,  4.32757027e-02,\n",
       "       -1.33844716e-02,  7.26311782e-06, -5.66090597e-03,  5.07286675e-02,\n",
       "        4.70942352e-03,  2.65480038e-02, -6.11170270e-02,  8.96223664e-01,\n",
       "       -4.62108627e-02, -2.56462812e-01,  1.33210212e-01,  4.47214901e-01,\n",
       "       -3.07969123e-01,  1.42379748e-02, -1.33383289e-01,  3.49293947e-01,\n",
       "        5.04339598e-02, -2.37676520e-02, -2.59640981e-02, -4.95776713e-01,\n",
       "       -1.01602525e-01,  2.35280976e-01, -9.69712615e-01,  5.67660332e-01,\n",
       "        1.43065751e-01,  1.42124640e-02,  5.88513732e-01, -2.73607224e-01,\n",
       "        1.69000223e-01,  1.54676825e-01,  2.07075417e-01, -2.87804268e-02,\n",
       "        1.38141577e-05, -6.15064315e-02,  4.16748747e-02, -1.16062896e-04,\n",
       "       -3.97272594e-02, -5.68113863e-01,  6.02727354e-01, -1.69804439e-01,\n",
       "        1.69194750e-02,  5.79919331e-02,  1.86641403e-02, -1.14388340e-05,\n",
       "        3.94161254e-01,  8.82430732e-01,  1.38182834e-01, -6.98341489e-01,\n",
       "       -1.55580744e-01,  7.70884454e-01,  4.42961186e-01,  2.37148523e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_val[2][1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
